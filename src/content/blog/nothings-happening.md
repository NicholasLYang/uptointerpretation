---
title: "Nothing's Happening"
pubDate: "Feb 23, 2026"
date: 2026-02-23T16:53:19-04:00
draft: false
---

It's funny when you go on two social media platforms and get two radically different views of the world. Go on Twitter and you'd think AI is completely taking over the world. Nobody's writing code manually, they're all running fifteen Claude instances in Gastown with Ralph Wiggum[^1] and beads, AI is completely changing software engineering forever.

[^1]: Y'know, I'm usually one for fun naming but Ralph Wiggum truly stretches my tolerance.

Whereas, if you go on reddit, you get a bunch of people saying it's just hype, and AI code is always trash. /r/ExperiencedDevs is an especially intense place for this sentiment. You'll get someone occasionally admitting that they do use AI agents, but only after emphasizing that they always produce bad code and senior engineers all look down on them.

Usually when I see such hype and such anti-hype, I tend to believe the anti-hype more. If people are saying crypto is the future, I'll believe the crypto skeptics. Ditto AR/VR, ditto Big Data. But idk, I have used the AI tools and goddamn it they are amazing. They can use niche languages, custom libraries, and solve complicated problems with ease. Actually, one thing that's interesting about complicated problems is that often they're not so complicated to solve. But before, that would only come after you've thought a lot, made a couple iterations, and refined your solution. Now, AI can figure out the simple solution faster.

AI is certainly not perfect, and I generally do roll my eyes a little at the exaggerated, over-the-top rhetoric on Twitter, but y'know what? Credit where credit is due. If I explained how AI agents worked right now in early 2026 to myself in early 2025, I'd call it exaggerated and over-the-top. Agents have their limits, but the trajectory of their improvement should give anyone pause.

But enough of the Twitter AI discourse, let's look at the redditors. They're the more fascinating crowd psychologically. I can sympathize deeply with their dismissiveness. The implications of AI coding agents are pretty hard to accept. It's hard to discover that your job is at serious risk of becoming obsolete, your industry at serious risk of being disrupted. Even if software engineering as a career survives, which I do think it will, it will not survive unscathed. There will be massive changes to how people do the job, to how software engineers are perceived, to the economic and social structures of our industry. These changes will be scary. They will hurt people's livelihoods and change people's lives. I see how it's tempting to write AI off as simply another hype cycle that will go away.

I think there's also this struggle because AI erases so much of what us programmers hold dearly; the arcane trivia of software engineering; the elegance of refactoring and reworking some code; the feeling of solving a problem and typing out the solution as fast as you can. Even within my short career, I've noticed [stuff made irrelevant](https://uptointerpretation.com/posts/things-i-used-to-care-about/) by technology. AI is accomplishing this at a significantly faster clip. 

It's like when formatters came on the scene. I remember a colleague who argued vehemently against them, because he cared so much about this particular alignment or that specific spacing. I doubt that any of those rules he had built really affected his code's legibility. But they were how he could determine good code. It's easy now, with years of hindsight, to dismiss this viewpoint. But it really mattered at the time! I imagine there's going to be similar, albeit way larger losses from AI.

Maybe a good analogy is electric bikes. Hardcore bicyclists used to have trails that were only for them. The trails required a certain amount of training and devotion to complete. But once electric bikes became popular, these trails became available to anyone who wished to visit them. The necessary sacrifice and the resulting reward became decoupled. Now, this is not quite the same for programmers and AI agents, since a good programmer with an AI agent is still vastly more effective than a weak programmer with an AI agent. But it's a closer analogy than I'd like! People with very little knowledge can produce complete, complicated products. They can do stuff in one Claude session that would have taken me a solid week and some really hard thinking. What was once reserved for a rare few is now made common, almost pedestrian.

I also find it fascinating how much moral judgement is attached to the AI discourse. The commenters mention that they use AI agents, but immediately with a caveat that they produce bad code and must always be babysat. It's almost like they're admitting a guilty pleasure. Perhaps this is the biking analogy at work. There's more moral purity in peddling towards the destination, rather than steering an electric bike. If we remove the moral purity, then we risk acknowledging that the destination is the same, regardless of our exact methodology.

Of course, with biking there's the element of physical fitness. Stop biking and your physical fitness will decline. There's been some evidence of this for agents too. Stop coding and your problem solving skills may atrophy. But will that matter? Perhaps it won't. The electric cyclists don't care that they're missing out on hypothetical fitness as long as they get to see the same sights. Perhaps there will be a generation of programmers who don't have the same problem solving skills, who don't know how to spot a missing semicolon, who won't know print statement debugging, who won't be able to write a binary search by hand. [The Story of Mel](https://users.cs.utah.edu/~elb/folklore/mel.html) comes to mind.

Perhaps there's enough solace in denial. I don't know. I'm not saying one must like these changes, but I find it harder and harder to understand dismissing them outright.
